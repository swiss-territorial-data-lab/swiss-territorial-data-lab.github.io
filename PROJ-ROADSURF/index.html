
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.21">
    
    
      
        <title>Classification of road surfaces - Swiss Territorial Data Lab</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.66ac8b77.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#classification-of-road-surfaces" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Swiss Territorial Data Lab" class="md-header__button md-logo" aria-label="Swiss Territorial Data Lab" data-md-component="logo">
      
  <img src="../assets/logo-stdl-transparent.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Swiss Territorial Data Lab
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Classification of road surfaces
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/swiss-territorial-data-lab" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    STDL on Github
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Swiss Territorial Data Lab" class="md-nav__button md-logo" aria-label="Swiss Territorial Data Lab" data-md-component="logo">
      
  <img src="../assets/logo-stdl-transparent.svg" alt="logo">

    </a>
    Swiss Territorial Data Lab
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/swiss-territorial-data-lab" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    STDL on Github
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Homepage
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/swiss-territorial-data-lab" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GitHub
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      1. Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-data" class="md-nav__link">
    <span class="md-ellipsis">
      2. Data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-area-of-interest" class="md-nav__link">
    <span class="md-ellipsis">
      2.1. Area of interest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-swisstlm3d" class="md-nav__link">
    <span class="md-ellipsis">
      2.2. swissTLM3D
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-swissimage-rs" class="md-nav__link">
    <span class="md-ellipsis">
      2.3. SWISSIMAGE RS
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-preprocessing" class="md-nav__link">
    <span class="md-ellipsis">
      3. Preprocessing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Preprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-generation-of-the-road-domain" class="md-nav__link">
    <span class="md-ellipsis">
      3.1. Generation of the Road Domain
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-raster-mosaic-generation" class="md-nav__link">
    <span class="md-ellipsis">
      3.2. Raster Mosaic Generation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-machine-learning-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      4. Machine Learning Analysis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Machine Learning Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-methodology" class="md-nav__link">
    <span class="md-ellipsis">
      4.1. Methodology
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-results" class="md-nav__link">
    <span class="md-ellipsis">
      4.2. Results
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-discussion" class="md-nav__link">
    <span class="md-ellipsis">
      4.3. Discussion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-deep-learning-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      5. Deep Learning Analysis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Deep Learning Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-methodology" class="md-nav__link">
    <span class="md-ellipsis">
      5.1. Methodology
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-results" class="md-nav__link">
    <span class="md-ellipsis">
      5.2. Results
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-discussion" class="md-nav__link">
    <span class="md-ellipsis">
      5.3. Discussion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      6. Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-references" class="md-nav__link">
    <span class="md-ellipsis">
      7. References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="classification-of-road-surfaces">Classification of road surfaces<a class="headerlink" href="#classification-of-road-surfaces" title="Permanent link">&para;</a></h1>
<p>Gwenaëlle Salamin (swisstopo), Clémence Herny (Exolabs), Roxane Pott (swisstopo), Alessandro Cerioni (État de Genève) <br></p>
<p>Proposed by the Federal Office of Topography swisstopo - PROJ-ROADSURF <br>
August 2022 to March 2023 - Published on August 28, 2023 <br>
All scripts are available on GitHub: https://github.com/swiss-territorial-data-lab/proj-roadsurf</p>
<p><b>Abstract</b>: The Swiss road network extends over 83’274 km. Information about the type of road surface is useful not only for the Swiss Federal Roads Office and engineering companies, but also for cyclists and hikers. Currently, the data creation and update is entirely done manually at the Swiss Federal Office of Topography. This is a time-consuming and methodical task, potentially suitable to automation by data science methods. The goal of this project is classifying Swiss roads according to their surface type, natural or artificial. <br>
We first searched for statistical differences between these two classes, in order to then perform supervised classification based on machine-learning methods. As we could not find any discriminant feature, we used deep learning methods. <br>
In terms of balanced F1 score, we obtained a global score of 0.74 over the training, validation and test area, 0.56 over the inference-only area.</p>
<h2 id="1-introduction">1. Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">&para;</a></h2>
<p>The Swiss road network extends over 83'274 km <sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>. Not only cyclists and hikers can be interested in knowing whether a given road section is covered by a natural or an artificial surface, but also the Swiss Federal Roads Office, which is in charge of road maintenance, and engineering companies. This information is found within the swissTLM3D <sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup> dataset, the large-scale topographic model of Switzerland produced by the Federal Office of Topography (swisstopo). Keeping the swissTLM3D dataset up to date is a time-consuming work that has to be done methodically. Operators draw and georeference new elements and fill in their attributes based on the visual interpretation of stereoscopic aerial images. The update of existing elements also follows this manual approach. Data science can help by autmatizing this time-consuming and systematic tasks.</p>
<p>So far, the majority of data science studies on the identification of the road surface type, in particular those based on artificial intelligence, have been conducted in the context of improving the driving and security of autonomous vehicles <sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup><sup id="fnref:4"><a class="footnote-ref" href="#fn:4">4</a></sup><sup id="fnref:5"><a class="footnote-ref" href="#fn:5">5</a></sup><sup id="fnref:6"><a class="footnote-ref" href="#fn:6">6</a></sup>. These works rely on images shot by cameras mounted at the front of the moving vehicle itself. To our knowledge, only one study, carried out by Mansourmoghaddam et al. (2022) <sup id="fnref:7"><a class="footnote-ref" href="#fn:7">7</a></sup>, proposed a method based on object-based classification from aerial imagery, which could successfully tell artificial roads from natural ones. Another possible approach is to use spectral indices, as done by Zhao &amp; Zhu (2022) <sup id="fnref:8"><a class="footnote-ref" href="#fn:8">8</a></sup> working on the distinction between artificial surfaces and bare land. However, their method is not specifically designed for road surfaces.</p>
<p>The goal of this project was to determine whether the road cover is artificial or natural with the development of data science tools. For this first test, only the roads of the class "3m Strasse" are considered. <br></p>
<figure align="center">
    <image src="images/proj_roadsurf_flow.jpeg" alt="Simplified workflow" style="width:75%"></image>
    <figcaption align="center"> <i>Figure 1: Overview of the workflow for this project. </i></figcaption>
</figure>

<p>As the location of roads was known, we faced a problem of supervised classification. Two approaches were tested to address it: machine learning (ML) and deep learning (DL). Both approaches used the same input data, aerial images and vector road location.</p>
<h2 id="2-data">2. Data<a class="headerlink" href="#2-data" title="Permanent link">&para;</a></h2>
<p>As input data, this project used two datasets produced by the Federal Office of Topography: swissTLM3D and SWISSIMAGE RS. We worked with data for the year 2018, for which the images and ground truth, <em>i.e.</em> the manually vectorized and classified roads, are available for the area of interest (AOI). Coordinates are expressed in the EPSG:2056 reference system.</p>
<h3 id="21-area-of-interest">2.1. Area of interest<a class="headerlink" href="#21-area-of-interest" title="Permanent link">&para;</a></h3>
<figure  align="center">
    <image src="images/AOI.jpeg" alt="Area of interest" style="width:75%"></image>
    <figcaption align="center"> <i>Figure 2: Delimitation of the area of interest with the tile numbers of the 1:25'000 Swiss national map. </i></figcaption>
</figure>

<p>The area of interest (AOI) defined for this study was represented by the tiles 1168, 1188, 1208 and 1228 of the Swiss national map at a scale of 1:25'000. This zone covers an area of 840 km<sup>2</sup> and was chosen because of its representativeness of the Swiss territory. <br></p>
<h3 id="22-swisstlm3d">2.2. swissTLM3D<a class="headerlink" href="#22-swisstlm3d" title="Permanent link">&para;</a></h3>
<p>The <a href="https://www.swisstopo.admin.ch/en/geodata/landscape/tlm3d.html">swissTLM3D</a> <sup id="fnref2:2"><a class="footnote-ref" href="#fn:2">2</a></sup> dataset is a large-scale topographic model of Switzerland. It contains geospatial data necessary o the national map, such as roads, buildings and land cover. Periodical updates rely on the manual work of specialized operators. They interpret stereoscopic images and fill in attributes with the help of some additional information, like cadastral surveys and terrestrial images. The specification of aerial imagery is similar to the <a href="#swissimage-rs">SWISSIMAGE RS</a> product. <br>
The road layer contains lines with the identifier, the structure (none, bridge, tunnel, etc.), the object type (highways, 8m roads, 1 m paths, etc.) and the surface type as attributes. The two possible classes of the surface type are defined in the metadata: artificial (German: Hart) and natural (Natur). The artificial class contains surfaces of hard artificial materials like asphalt, concrete or slabs. The natural class contains roads with a surface of natural materials like gravel or dirt, and untreated surfaces.</p>
<p>In this project, it was decided to test the classification for the type "3m Strasse" (3 m roads). This class encompasses roads that are between 2.81 m and 4.20 m wide. Within this subset, 6486 roads have an artificial surface and 289 a natural one. The dataset is heavily unbalanced toward the artificial roads.</p>
<p>In addition, the swissTLM3D dataset was used to identify the forests. Indeed, they prevent us from observing roads from aerial images; hence those roads cannot be used in our study. As no layer in the swissTLM3D is specifically devoted to forested areas, they were deduced from the land cover classes. A filter was applied to only keep forests ("Wald") and open forests ("Wald offen").</p>
<p>Over the AOI, all the roads in quarries have a natural surface. We used our own layer from <a href="https://tech.stdl.ch/PROJ-DQRY/">the project on the detection of mineral extraction sites</a> to know their location. However, it is possible to use the information on the area of use from the swissTLM3D dataset which has a class on gravel quarries and one on stone quarries.</p>
<h3 id="23-swissimage-rs">2.3. SWISSIMAGE RS<a class="headerlink" href="#23-swissimage-rs" title="Permanent link">&para;</a></h3>
<p>The product <a href="https://www.swisstopo.admin.ch/en/geodata/images/ortho/swissimage-rs.html">SWISSIMAGE RS</a> <sup id="fnref:9"><a class="footnote-ref" href="#fn:9">9</a></sup> contains aerial images of Switzerland composed by four bands: near-infrared (NIR), red &#40;R), green (G) and blue (B). The ground resolution equals 0.10 m over the area of interest, except in some high altitude regions or regions with complex topography, where a resolution of 0.25 m is deemed sufficient. The standard deviation is +/- 0.15 m (1 sigma) for a ground resolution of 0.10 m and +/- 0.25 m (1 sigma) for a ground resolution of 0.25 m, +/- 3-5 m (1 sigma). The dataset is composed of a collection of 16-bit encoded GeoTIFF orthorectified images. The overlap between images varies, but stays always present.</p>
<h2 id="3-preprocessing">3. Preprocessing<a class="headerlink" href="#3-preprocessing" title="Permanent link">&para;</a></h2>
<p>Both the swissTLM3D and SWISSIMAGE RS dataset were processed to be suitable for the algorithms we wanted to develop. This was achieved with two procedures: the generation of the road domain and the creation of a raster mosaic. </p>
<h3 id="31-generation-of-the-road-domain">3.1. Generation of the Road Domain<a class="headerlink" href="#31-generation-of-the-road-domain" title="Permanent link">&para;</a></h3>
<p>The swissTLM3D contains a vector layer representing every road section as a 3D line with some attached attributes. As a first test, the beneficiaries requested us to perform the analysis only on roads of the type "3m Strasse", <em>i.e</em> the roads wider than 2.81 m and thinner than 4.20 m. The engineered structures were excluded based on the attribute "KUNSTBAUTE". Only bridges and road sections without structures were kept. <br>
Data preparation differs slightly between the two performed analyses, machine and deep learning. Results for both approaches are shown here below.</p>
<figure  align="center">
    <image src="images/roads_transformation_stats.jpeg" alt="Road labels for the machine learning."></image>
    <figcaption align="center"><i>Figure 3: Resulting labels (left) from the initial TLM lines (right) in the case of the machine learning. </i></figcaption>
</figure>

<figure  align="center">
    <image src="images/roads_transformation_OD.jpeg" alt="Road labels for the deep learning."></image>
    <figcaption align="center"><i>Figure 4: Resulting labels (left) from the initial TLM lines (right) in the case of deep learning. </i></figcaption>
</figure>

<p>For the machine learning analysis, only the 3m roads were kept (figure 3). For the deep learning analysis, we judged safer to keep all the visible roads (figure 4). Therefore, the neighboring roads were also considered. We made the hypothesis that we would obtain better results by training the model on all the visible roads, rather than on the 3m ones only. Still, the focus on "3m Strasse" class was enforced through the selection of raster tiles: only those tiles containing the specific class were used as input data. <br>
Road geometries, originally linear, were transformed into polygons by adding a buffer with a flat cap style. This procedure generated unwanted overlapping areas in the neighborhood of the intersection points between contiguous road sections. Such artifacts were handled differently depending on the road types:</p>
<ul>
<li>in the case of roads with different widths, the zone of the overlap inherited the class of the widest road section among the intersecting ones.</li>
<li>in the case of roads with the same width,<ul>
<li>in the case of the machine learning analysis, overlapping parts were discarded;</li>
<li>in the case of the deep learning analysis, it was supposed that leaving the overlapping parts would produce more understandable labels for the algorithm than suppressing the overlap.</li>
</ul>
</li>
</ul>
<p>Once that the polygons were generated, sections hidden by a forest canopy were excluded. A buffer of 2 m was also added around forests as the canopy was often seen to be extending beyond the forest delimitation as recorded in the swissTLM3D dataset. <br></p>
<p>We considered adding some information about the altitude of the length of the roads to the labels. Natural and artificial roads share pretty much the same distribution in terms of altitude. For the length, the longest roads all had an artificial surface. However, the experts could not tell us if it was the case for all Switzerland or a coincidence on our AOI. <br>
For the deep learning analysis, we tried to improve the overlap between labels and images by taking cadastral data into account. A larger buffer was used on the lines for the TLM. Then, only the parts of the buffer intersecting the road surfaces from cadastral surveying were kept. As described in the <a href="#5-deep-learning-analysis">deep learning analysis section</a>, we tested the labels straight out of the TLM and the ones augmented by the cadastral surveying. We also tried to merge the labels by width type or by surface type.<br></p>
<p>After the pre-processing step described here above, </p>
<ul>
<li>for the machine learning analysis, 2'781 road sections were obtained, including 110 natural ones;</li>
<li>for the deep learning analysis, 12'208 road sections were obtained, including 3078 natural ones. </li>
</ul>
<p>Let us remind that there were many more roads labeled in the second case as we considered all the visible roads. Especially for natural roads, the vast majority did not belong to the class of interest, but rather to the "1m Weg" and "2m Weg" classes. <br></p>
<h3 id="32-raster-mosaic-generation">3.2. Raster Mosaic Generation<a class="headerlink" href="#32-raster-mosaic-generation" title="Permanent link">&para;</a></h3>
<p>As said in the description of <a href="#swissimage-rs">SWISSIMAGE RS</a>, a large overlap between images is present in the dataset. To remove this overlap, a mosaic was created. Instead of merging all the images into one, we decided to set up a XYZ raster tile service, allowing us to work at different resolutions.<br>
The first step consists in reprojecting images in the EPSG:3857 projection, compliant with standard <a href="https://en.wikipedia.org/wiki/Tiled_web_map">tile map services</a>. Then, to save memory and disk space, images were converted from 16 to 8 bits. Besides, normalization was performed to optimize the usage of the available dynamic range. Finally, images were exported to the Cloud-Optimized GeoTIFF (COG) format. COG files can then be loaded by the TiTiler application, an Open Source dynamic tile server application <sup id="fnref:10"><a class="footnote-ref" href="#fn:10">10</a></sup>. The MosaicJSON specification was used to store image metadata <sup id="fnref:11"><a class="footnote-ref" href="#fn:11">11</a></sup>. Zoom levels were bound between 17 and 20, corresponding to resolutions between 1.20 m and 0.15 m.</p>
<h2 id="4-machine-learning-analysis">4. Machine Learning Analysis<a class="headerlink" href="#4-machine-learning-analysis" title="Permanent link">&para;</a></h2>
<h3 id="41-methodology">4.1. Methodology<a class="headerlink" href="#41-methodology" title="Permanent link">&para;</a></h3>
<p>Before delving into machine learning, we performed some exploratory data analysis, aiming at checking whether already existing features were discriminant enough to tell natural roads from artificial ones. Additional predictive features were also generated, based on </p>
<ul>
<li>ratios between pixel values in different bands (G/R, B/R, NIR/R, G/B, G/NIR, B/NIR);</li>
<li>one spectral index;</li>
<li>per-band statistics (mean, median, minimum, maximum, standard deviation).</li>
</ul>
<p>The machine learning analysis was performed only on the two middle tiles of the AOI.</p>
<p>The most promising spectral index we found in the literature is the Artificial Surface Index (ASI) defined by Zhao &amp; Zhu (2022) <sup id="fnref:12"><a class="footnote-ref" href="#fn:12">12</a></sup>. Unfortunately, the computation of the ASI requires the shortwave infrared (SWIR) band which is not available in the SWISSIMAGE RS data. The SWIR band can be available in satellite imagery (e.g.: Landsat 8, Sentinel 2), yet spatial resolution (20-30 m/px) is not enough for the problem at hand.</p>
<p>Instead, the VgNIR-BI index <sup id="fnref:13"><a class="footnote-ref" href="#fn:13">13</a></sup> could be computed in our case, since it combines the green and NIR bands:</p>
<div class="arithmatex">\[\begin{align}
\
    \mbox{VgNIR-BI} = {\rho_{green} - \rho_{NIR} \over \rho_{green} + \rho_{NIR}}
\
\end{align}\]</div>
<p>where &#961; stands for the atmospherically corrected surface reflectance values of the band. In our case, no atmospheric correction was applied, because we dealt with aerial imagery instead of satellite imagery.</p>
<p>Boxplots were generated to visualize the distribution of the aforementioned predictive features. Principal component analysis (PCA) were performed, too. The group of values passed to the PCA were the following:
- pixel values: Each pixel displays 11 attributes corresponding to (1) its values on the different bands (R, G, B, NIR), (2) the ratio between bands (G/R, B/R, NIR/R, G/B, G/NIR, B/NIR), and (3) the VgNIR-BI spectral index <sup id="fnref2:13"><a class="footnote-ref" href="#fn:13">13</a></sup>.
- summary statistics: Each road has 5 attributes for each band: the mean, the median, the minimum (min), the maximum (max), and the standard deviation (std).</p>
<p>Let us note that:</p>
<ol>
<li>these two analyses were carried out on a curated selection of input data, which was ought to maximize the separation between natural and artificial roads. The road sections were filtered by pixel number and margin of error on their mean to avoid small or crowded road sections. <br>
Were the results promising, the analysis would have been carried out on the entire dataset.</li>
<li>We confirmed that results were not biased by performing each analysis on the entire dataset and a balanced subset.</li>
<li>We also confirmed that results were stable with respect to the chosen zoom level.</li>
</ol>
<h3 id="42-results">4.2. Results<a class="headerlink" href="#42-results" title="Permanent link">&para;</a></h3>
<p>In order not to make the presentation too cumbersome, here we only show results produced at zoom level 18, on the entire dataset, and considering road sections corresponding to the following criteria:</p>
<ol>
<li>covering at least 10 pixels;</li>
<li>enjoying a margin of error (MOE) on the mean below 12.5, computed with a coefficient level of 0.95.</li>
</ol>
<figure  align="center">
    <image src="images/boxplot_pixel_in_bands.webp" alt="Boxplots of the distribution of pixel values on each band for each type of surface"></image>
    <figcaption  align="center"><i>Figure 5: Boxplots of the statistical distribution of pixel values on each band for each surface type. Each graph represents a band and each boxplot a surface type. </i></figcaption>
</figure>

<p>We can see on the figure 5 that both the median and the upper quartile are systematically higher for natural than for artificial roads across all the bands, meaning the natural roads have brighter parts. Unfortunately, we have that pixel value statistics do not allow a sharp distinction between the two classes, as the lower quartile are very close.</p>
<figure  align="center">
    <image src="images/boxplot_pixel_in_bands_ratio_part1.webp" alt="Boxplots of the ratios and index for each type of surface"></image>
    <figcaption  align="center"><i>Figure 6: Boxplots of the pixel distribution on the VgNIR-BI index and the ratios between bands. Each graph represents a ratio or the index and each boxplot a surface type. </i></figcaption>
</figure>

<figure  align="center">
    <image src="images/boxplot_pixel_in_bands_ratio_part2.webp" alt="Boxplots of the ratios and index for each type of surface"></image>
    <figcaption  align="center"><i> Figure 6bis: Boxplots of the pixel distribution on the ratios between bands. Each graph represents a ratio and each boxplot a surface type. </i></figcaption>
</figure>

<p>The ratios between bands and the VgNIR-BI present similar values for the artificial and natural roads, allowing no distinction between the classes.</p>
<figure  align="center">
    <image src="images/boxplot_stats_band_blue.webp" alt="Boxplots of road statistics on the blue band"></image>
    <figcaption  align="center"><i>Figure 7: Boxplots of the distribution for the road summary statistics on the blue band. Each graph represents a statistic and each boxplot a type of road surface. </i></figcaption>
</figure>

<p>Boxplots produced with the summary statistics computed per band and per road section lead to similar conclusions. Natural roads tend to be lighter than artificial ones. However, the difference is not strong enough to affect the lower quartiles and allow a sharp distinction between classes. <br></p>
<figure  align="center">
    <image src="images/PCA_pixels_PC12_individuals.jpg" alt="PCA of the pixels based on their value on each band" style="width:75%"></image>
    <figcaption align="center"><i>Figure 8: PCA of the pixels based on their value on each band. </i></figcaption>
</figure>

<figure  align="center">
    <image src="images/PCA_stats_band_blue_PC12_individuals.jpg" alt="PCA of the pixels based on their value on each band" style="width:75%"></image>
    <figcaption align="center"><i>Figure 9: PCA of the roads based on their statistics on the blue band.</i></figcaption>
</figure>

<p>The figures 8 and 9 present respectively the results of the PCA on the pixel values and on the statistics over road sections. Once more, we have to acknowledge that, unfortunately, artificial and natural roads cannot be separated.</p>
<h3 id="43-discussion">4.3. Discussion<a class="headerlink" href="#43-discussion" title="Permanent link">&para;</a></h3>
<p>Although boxplots reveal that some natural roads can be brighter than artificial roads, statistical indicators overlap in such a way that no sharp distinction between the two classes can be drawn. The PCA confirms such an unfortunate finding.</p>
<p>Those results are not surprising. As a matter of fact, natural roads which are found in the "3m Strasse" type are mainly made by gravel or similar materials which, color-wise, make them very similar to artificial roads.</p>
<h2 id="5-deep-learning-analysis">5. Deep Learning Analysis<a class="headerlink" href="#5-deep-learning-analysis" title="Permanent link">&para;</a></h2>
<h3 id="51-methodology">5.1. Methodology<a class="headerlink" href="#51-methodology" title="Permanent link">&para;</a></h3>
<p>To perform the detection and classification of roads, the object detector (OD) framework developed by the STDL <sup id="fnref:14"><a class="footnote-ref" href="#fn:14">14</a></sup> was used. It is described in details <a href="https://tech.stdl.ch/TASK-IDET/">in the dedicated page</a>.  <br></p>
<p>The two central parts of the AOI constitute the training zone, i.e. the zone for the training, validation and test datasets. The two exterior parts constitute the inference-only zone, i.e. for the "other" dataset, to test the trained model on an entirely new zone. <br></p>
<p>To assess the predictions, a script was written, <code>final_metrics.py</code> instead of using the one directly from the STDL's OD. We decided to take advantage that:
1. Predictions are not exclusive between classes. Every road section was detected several times with predictions of different class overlapping. 
2. The delimitation of the roads are already known.</p>
<p>Therefore, rather than choosing one correct prediction, we aggregated the predictions in a natural and an artificial index over each label. Those indices were defined as follows: </p>
<div class="arithmatex">\[\begin{align}
\
        \mbox{index}_{class} = \frac{\sum_{i=1}^{n} (A_{\%,i} \cdot \mbox{score}_{class,i})}{\sum_{i=1}^{n} A_{\%,i}}
\
\end{align}\]</div>
<p>where <em>n</em> is the number of predictions belonging to the class, <span class="arithmatex">\(A_{\%, i}\)</span> is the percentage of overlapping area between the label and the prediction, <span class="arithmatex">\(\mbox{score}_{class,i}\)</span> is its confidence score. <br></p>
<div class="arithmatex">\[\begin{align}
\
    \text{final class} =
        \begin{cases}
            \mbox{artificial} \quad \mbox{ if } \quad \mbox{index}_{artificial} \gt \mbox{index}_{natural}\\
            \mbox{natural} \quad \mbox{ if } \quad \mbox{index}_{artificial} \lt \mbox{index}_{natural} \\
            \mbox{undetected} \quad \text{ if } \quad \mbox{index}_{artificial} = 0 \; \text{ and } \; \mbox{index}_{natural} = 0 \\
            \mbox{undetermined} \quad \text{ if } \quad \mbox{index}_{artificial} = \mbox{index}_{natural} \; \text{ and }\; \mbox{index}_{artificial} \neq 0\\
        \end{cases}
\
\end{align}\]</div>
<p>The largest index indicates the right class as better predictions are supporting it. <br>
Once every road has an attributed class, the result was evaluated in terms of recall, precision and balanced F1 score. <br></p>
<div class="arithmatex">\[\begin{align}
\
    P_{class} = \frac{TP_{class}}{TP_{class}+FP_{class}} \text{ and } P = \frac{P_{natural} + P_{artificial}}{2}
\
\end{align}\]</div>
<div class="arithmatex">\[\begin{align}
\
    R_{class} = \frac{TP_{class}}{TP_{class}+FN_{class}} \text{ and } R = \frac{R_{natural} + R_{artificial}}{2}
\
\end{align}\]</div>
<div class="arithmatex">\[\begin{align}
\
    F1\text{ }score = \frac{2PR}{P + R}
\
\end{align}\]</div>
<p>where</p>
<ul>
<li><span class="arithmatex">\(FN_{class}\)</span> is the number of roads that are not detected or wrongly assigned to the other class,</li>
<li><span class="arithmatex">\(FP_{class}\)</span> is the number of roads from the other class wrongly attributed to the considered class,</li>
<li><span class="arithmatex">\(P_{class}\)</span> is the precision, <i>i.e.</i> the percentage of correct roads in the detected class,</li>
<li><span class="arithmatex">\(R_{class}\)</span> is the recall, <i>i.e.</i> the percentage of correctly found and classified roads from a class,</li>
<li><span class="arithmatex">\(TP_{class}\)</span> is the number of roads correctly found in the class.</li>
</ul>
<p>The predictions are not necessarily all taken into account. They are filtered based on their confidence score. Thresholds were tested over the balanced F1 score of the validation dataset. <br></p>
<p>The current dataset exhibits a very strong class imbalance. Therefore, we decided to use balanced metrics, giving the same weight to both classes. The balanced F1 score was chosen as the determining criterion between the different tested models. <br>
As it gives equal weight to both classes, the quality of the classification for the natural road was well taken into consideration. However, we have to keep in mind that we gave great importance to this class compared to its number of individuals. <br></p>
<p>A great risk exists that the model would be biased toward artificial roads, because of the imbalance between classes. Therefore, we decided on a baseline model (BLM) where all the roads in the training zone are classified as artificial. Its metrics are the following: <br></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Artificial</th>
<th style="text-align: center;">Natural</th>
<th style="text-align: center;">Global</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Precision</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.49</td>
</tr>
<tr>
<td style="text-align: left;">Recall</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr>
<td style="text-align: left;">F1 score</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.49</td>
</tr>
</tbody>
</table>
<p><i>Table 1: Metrics for the BLM with all the roads classified as artificial</i></p>
<p>The trained models should improve the global F1 score of 0.49 to be considered as an improvement. <br></p>
<p>Finally, we wanted to know if the artificial and natural index could constitute a confidence score for their respective classes. The reliability diagram has been plotted to visualize the accuracy of the classification at different levels of those indices. <br></p>
<figure align="center">
    <image src="images/test_parameters.jpg" alt="Representation of the different tests carried out" style="width:75%"></image>
    <figcaption align="center"><i>Figure 10: Listing of the various tests carried out. </i></figcaption>
</figure>

<p>To achieve the best possible results, several input parameters and files for the model training were tested.
1. We tried to improve the quality of the labels by integrating data from cadastral surveying and by merging the roads based on their cover, on their type, or not at all.
2. We trained the model with different zoom level images, from 17 to 20. 
3. The influence of different band combinations on the model performance was investigated: true colors (RGB) and false colors (NirRG).</p>
<p>For each test, the best configuration was chosen based on the global balanced F1 score. This method supposes that the best choice for one parameter did not depend on the others.</p>
<h3 id="52-results">5.2. Results<a class="headerlink" href="#52-results" title="Permanent link">&para;</a></h3>
<p>When testing different procedures to create the labels, using only the TLM and excluding the data from the cadastral survey gave the best metrics. Besides, cutting the label corresponding to the road sections and not merging them by road type or surface gave better metrics. <br>
Increasing the zoom level improved the balanced F1 score. <br>
Using the bands RGB and RG with NIR gave very similar results and an equal F1 score. <br>
Therefore, the best model is based on labels deduced from the TLM and using the RGB bands at a zoom level 20.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Artificial</th>
<th style="text-align: center;">Natural</th>
<th style="text-align: center;">Global</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Precision</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.87</td>
</tr>
<tr>
<td style="text-align: left;">Recall</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.86</td>
</tr>
<tr>
<td style="text-align: left;">F1 score (1)</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.86</td>
</tr>
<tr>
<td style="text-align: left;"><em>F1 score for the BLM</em> (2)</td>
<td style="text-align: center;"><em>0.98</em></td>
<td style="text-align: center;"><em>0</em></td>
<td style="text-align: center;"><em>0.49</em></td>
</tr>
<tr>
<td style="text-align: left;">Improvement: (1)-(2)</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.32</td>
</tr>
</tbody>
</table>
<p><i>Table 2: metrics for the best model over the training, test and validation area.</i></p>
<p>The F1 score for the natural roads and the global one outperformed the BLM. The per-class F1 scores has been judged as satisfying by the beneficiaries.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Artificial</th>
<th style="text-align: center;">Natural</th>
<th style="text-align: center;">Global</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Precision</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">0.60</td>
</tr>
<tr>
<td style="text-align: left;">Recall</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">0.61</td>
</tr>
<tr>
<td style="text-align: left;">F1 score (1)</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.24</td>
<td style="text-align: center;">0.60</td>
</tr>
<tr>
<td style="text-align: left;"><em>F1 score for the BLM</em> (2)</td>
<td style="text-align: center;"><em>0.98</em></td>
<td style="text-align: center;"><em>0</em></td>
<td style="text-align: center;"><em>0.49</em></td>
</tr>
<tr>
<td style="text-align: left;">Improvement: (1)-(2)</td>
<td style="text-align: center;">-0.02</td>
<td style="text-align: center;">0.24</td>
<td style="text-align: center;">0.11</td>
</tr>
</tbody>
</table>
<p><i>Table 3: metrics for the best model over the inference-only area.</i></p>
<p>Those metrics are worse than the ones obtained over the training area. The global F1 score is still higher than for the BLM. However, the natural F1 score is not high enough. <br></p>
<figure  align="center">
    <image src="images/barplots_new_zone.jpg" alt="Absolute and relative repartition of the roads in the inference-only zone" style="width:75%"></image>
    <figcaption align="center"><i>Figure 11: Absolute and relative repartition of the roads in the inference-only zone. </i></figcaption>
</figure>

<p>93.2% of the roads are correctly classified, 4.2% are in the wrong class and 2.6% are undetected or undetermined. Nearly half of the natural roads are either undetected or in the wrong class, but as they represent a tiny proportion of the dataset, they impact little the accuracy. <br>
In the training zone, only 2% of the roads are in the wrong class and 1.7% are undetected or undetermined. <br></p>
<figure  align="center">
    <image src="images/reliability_diagram.jpg" alt="Reliability curve for the training zone and the inference-only zone." style="width:75%"></image>
    <figcaption align="center"><i>Figure 12: Reliability curves for the training and the inference-only zone. </i></figcaption>
</figure>

<p>The artificial index can be used as confidence score for the artificial roads. The natural index can be used as confidence score for the natural ones. Indeed, the accuracy of the results for each class increases with their value.</p>
<h3 id="53-discussion">5.3. Discussion<a class="headerlink" href="#53-discussion" title="Permanent link">&para;</a></h3>
<p>The F1 score obtained is 0.86 over the area to train and validate the model and 0.60 over the rest of the AOI. The difference is essentially due to the decrease in the F1 score of the natural roads, passing from 0.74 to 0.24. <br>
The first intuition is that we were facing a case of overfitting. However, the validation loss was controlled in order to stop the training on time and avoid this problem. <br>
Another possibility would be that the two zones differ significantly and that a model trained on one cannot apply on the other. Hence, we also split the tiles randomly between the training and the inference-only zone. The gap between the balanced F1 score of the training and inference-only zone passed from 0.25 to 0.19 with the same hyper-parameters. <br> </p>
<p>The high recall for artificial roads indicates that the model properly detects them. However, once the artificial recall is high, the high artificial precision is in this case necessarily due. As the roads have a known location, the false positives not due to a class confusion are eliminated from our assessment. Then, only the roads classified in the wrong class can affect precision. As there are not a lot of natural roads, even if they were all wrongly classified as artificial like in the BLM, the precision would still remain well at 0.97. In the current case, the precision of the trained model is 0.01 higher than the one of the BLM. <br>
The drop in the natural F1 score is due to all the roads predicted in the wrong class. As they are only a few natural roads, errors of the model affect them more heavily. The part of the misclassified road increased by 44% between the training and the inference-only zone. Meanwhile, the part of undetermined roads only increased by 1% <br></p>
<p>The F1 score could maybe be further improved by focusing more strictly on the 3m roads. Indeed, we considered it would be safer to teach the algorithm to differentiate only between surfaces and not between road types, which are defined by width. Therefore, the tiles were selected because they intersected 3m roads, but then all the roads on the tiles were transformed into labels. Because of the rarity of 3m natural roads, most of the natural roads seen by the algorithm are 2m roads and those often have a surface with grass, where the 3m natural roads have a surface made only of gravel or dirt. Over the training zone, 110 natural roads are 3m ones and 1183 ones are 2 m and 1 m paths. Maybe, labelling only the 3m roads would give better results than labelling all the visible roads. <br>
 We did not tune the hyperparameter used by the deep learning model once we found a satisfying enough combination. In addition, as the algorithm is based on detectron2, not everything can easily be tuned. Using an entirely new framework and tuning the loss weights would allow better handling the class imbalance. A new framework could also allow integrating an attention mask and take advantage of the known road location like recommended by Epel (2018)<sup id="fnref:15"><a class="footnote-ref" href="#fn:15">15</a></sup>. Using a new framework could also allow to use images with 4 bands and integrating the NIR. However, we decided here to first try the tools we already had in our team.</p>
<p>We can say that there is a bias in the model encouraging it to predict artificial roads. However, it is still better than the BLM. Therefore, this model is adapted for its purpose. <br></p>
<h4 id="531-elements-specific-to-the-application-on-the-swisstlm3d-product">5.3.1. Elements specific to the application on the SwissTLM3D product<a class="headerlink" href="#531-elements-specific-to-the-application-on-the-swisstlm3d-product" title="Permanent link">&para;</a></h4>
<p>All these findings seem negative, which is why it is appropriate to recall the significant imbalance between the classes. If we look at the percentages, 93.2% of the dataset is correctly classified over the inference-only zone. This could represent a significant gain of time compared to an operator who would do the classification manually. Indeed, once the model trained, the procedure documented here only needs 20 minutes to classify the roads of the AOI. Besides, the artificial and natural indices allow us to find most of the misclassified roads and limit the time needed for a visual verification. <br>
In addition, the information of the road surface type is already available for the whole Switzerland. When using the algorithm to update the swissTLM3D dataset, it would be possible to perform change detection between the previous and new surface type. Then, those changes could be visually verified.</p>
<h2 id="6-conclusion">6. Conclusion<a class="headerlink" href="#6-conclusion" title="Permanent link">&para;</a></h2>
<p>Keeping the swissTLM3D dataset up to date is a time consuming and methodical task. This project aimed at finding  a method to automatize the determination of the road surface type (artificial vs. natural). We focused on roads belonging to the "3m Strasse" class and discovered that statistics stemming from pixel values are not enough discriminating to tell artificial roads from natural ones.  <br>
Therefore, we decided not to attempt any supervised classification based on machine learning. Instead, deep learning methods are performed. With 93% of the roads classified correctly, this method gave better results in regard to the global F1 score than a baseline model classifying all the roads as artificial. However, the model classifies 4.2% of the roads in the wrong class and has difficulties performing new zones. <br>
To ensure the quality of the swissTLM3D product, we advise to first perform a classification with the algorithm, then to check roads with a low class index or a change in surface type compared to the previous version years. It could represent a huge time saver for the operators who currently classify and check a second time all the roads. <br></p>
<p>Despite our investigations, we could not find the cause of the gap between the metrics for the training and the inference-only zone. Further investigation is needed.<br>
The next step for this project would be to extend the algorithm to paths of 1 to 2 m wide. The natural roads of 3 m are mostly made of gravel, which strongly resembles asphalt, while natural paths are mostly made of dirt and can grow grass. Therefore, when mixing the two road width classes in one model, the natural roads of 3 m could be too difficult to distinguish from artificial roads and end up neglected. </p>
<h2 id="7-references">7. References<a class="headerlink" href="#7-references" title="Permanent link">&para;</a></h2>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Office fédéral de la statistique. Longueur des routes en 2020 | Office fédéral de la statistique. https://www.bfs.admin.ch/news/fr/2020-0273, November 2020.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>swisstopo. swissTLM3D. https://www.swisstopo.admin.ch/de/geodata/landscape/tlm3d.html.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p>Lushan Cheng, Xu Zhang, and Jie Shen. Road surface condition classification using deep learning. <em>Journal of Visual Communication and Image Representation</em>, 64:102638, October 2019. <a href="https://doi.org/10.1016/j.jvcir.2019.102638">doi:10.1016/j.jvcir.2019.102638</a>.&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:4">
<p>Susi Marianingsih, Fitri Utaminingrum, and Fitra Abdurrachman Bachtiar. Road Surface Types Classification Using Combination of K-Nearest Neighbor and Naïve Bayes Based on GLCM. <em>International Journal of Advanced Software Computer Application</em>, 11(2):15–27, 2019.&#160;<a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:5">
<p>Marcus Nolte, Nikita Kister, and Markus Maurer. Assessment of Deep Convolutional Neural Networks for Road Surface Classification. In <em>2018 21st International Conference on Intelligent Transportation Systems (ITSC)</em>, 381–386. Maui, HI, November 2018. IEEE. <a href="https://doi.org/10.1109/ITSC.2018.8569396">doi:10.1109/ITSC.2018.8569396</a>.&#160;<a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
<li id="fn:6">
<p>Viktor Slavkovikj, Steven Verstockt, Wesley De Neve, Sofie Van Hoecke, and Rik Van De Walle. Image-Based Road Type Classification. In <em>2014 22nd International Conference on Pattern Recognition</em>, 2359–2364. Stockholm, August 2014. IEEE. <a href="https://doi.org/10.1109/ICPR.2014.409">doi:10.1109/ICPR.2014.409</a>.&#160;<a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text">&#8617;</a></p>
</li>
<li id="fn:7">
<p>Mohammad Mansourmoghaddam, Hamid Reza Ghafarian Malamiri, Fahime Arabi Aliabad, Mehdi Fallah Tafti, Mohamadreza Haghani, and Saeed Shojaei. The Separation of the Unpaved Roads and Prioritization of Paving These Roads Using UAV Images. <em>Air, Soil and Water Research</em>, 15:117862212210862, January 2022. <a href="https://doi.org/10.1177/11786221221086285">doi:10.1177/11786221221086285</a>.&#160;<a class="footnote-backref" href="#fnref:7" title="Jump back to footnote 7 in the text">&#8617;</a></p>
</li>
<li id="fn:8">
<p>Hailing Zhou, Hui Kong, Lei Wei, Douglas Creighton, and Saeid Nahavandi. On Detecting Road Regions in a Single UAV Image. <em>IEEE Transactions on Intelligent Transportation Systems</em>, 18(7):1713–1722, July 2017. <a href="https://doi.org/10.1109/TITS.2016.2622280">doi:10.1109/TITS.2016.2622280</a>.&#160;<a class="footnote-backref" href="#fnref:8" title="Jump back to footnote 8 in the text">&#8617;</a></p>
</li>
<li id="fn:9">
<p>swisstopo. SWISSIMAGE RS. https://www.swisstopo.admin.ch/fr/geodata/images/ortho/swissimage-rs.html.&#160;<a class="footnote-backref" href="#fnref:9" title="Jump back to footnote 9 in the text">&#8617;</a></p>
</li>
<li id="fn:10">
<p>TiTiler. https://developmentseed.org/titiler/.&#160;<a class="footnote-backref" href="#fnref:10" title="Jump back to footnote 10 in the text">&#8617;</a></p>
</li>
<li id="fn:11">
<p>Vincent Sarago, Sean Harkins, and Drew Bollinger. Developmentseed / mosaicjson-spec. https://github.com/developmentseed/mosaicjson-spec, 2021.&#160;<a class="footnote-backref" href="#fnref:11" title="Jump back to footnote 11 in the text">&#8617;</a></p>
</li>
<li id="fn:12">
<p>Yongquan Zhao and Zhe Zhu. ASI: An artificial surface Index for Landsat 8 imagery. <em>International Journal of Applied Earth Observation and Geoinformation</em>, 107:102703, March 2022. <a href="https://doi.org/10.1016/j.jag.2022.102703">doi:10.1016/j.jag.2022.102703</a>.&#160;<a class="footnote-backref" href="#fnref:12" title="Jump back to footnote 12 in the text">&#8617;</a></p>
</li>
<li id="fn:13">
<p>Ronald C. Estoque and Yuji Murayama. Classification and change detection of built-up lands from Landsat-7 ETM+ and Landsat-8 OLI/TIRS imageries: A comparative assessment of various spectral indices. <em>Ecological Indicators</em>, 56:205–217, September 2015. <a href="https://doi.org/10.1016/j.ecolind.2015.03.037">doi:10.1016/j.ecolind.2015.03.037</a>.&#160;<a class="footnote-backref" href="#fnref:13" title="Jump back to footnote 13 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:13" title="Jump back to footnote 13 in the text">&#8617;</a></p>
</li>
<li id="fn:14">
<p>Swiss Territorial Data Lab. Object detector. February 2023. URL: <a href="https://github.com/swiss-territorial-data-lab/object-detector">https://github.com/swiss-territorial-data-lab/object-detector</a>.&#160;<a class="footnote-backref" href="#fnref:14" title="Jump back to footnote 14 in the text">&#8617;</a></p>
</li>
<li id="fn:15">
<p>Sagi Eppel. Classifying a specific image region using convolutional nets with an ROI mask as input. December 2018. <a href="https://arxiv.org/abs/1812.00291">arXiv:1812.00291</a>.&#160;<a class="footnote-backref" href="#fnref:15" title="Jump back to footnote 15 in the text">&#8617;</a></p>
</li>
</ol>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020-2021 Swiss Territorial Data Lab
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/swiss-territorial-data-lab" target="_blank" rel="noopener" title="Repo on Github" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:<info@stdl.ch>" target="_blank" rel="noopener" title="Send us an eMail!" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.7l167.6-182.9c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.expand"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.a7c05c9e.min.js"></script>
      
        <script src="../assets/javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>